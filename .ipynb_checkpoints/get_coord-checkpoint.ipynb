{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the number of elements\n",
    "def count_elmt(df):\n",
    "    return len(df.index)\n",
    "\n",
    "# Text handling utilities\n",
    "from string import punctuation\n",
    "def lowercase_all(text):\n",
    "    return text.lower()\n",
    "def remove_punct(text):\n",
    "    return ''.join([ch for ch in text if ch not in punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Corrector\n",
    "\n",
    "Spelling Corrector based on the work of Peter Norvig: http://norvig.com/spell-correct.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('data/list_addresses.txt', encoding='utf-8').read())) \n",
    "#list_addresses.txt is a hand-corrected list of addresses\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if (w.isalpha() and w.lower() in WORDS))\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "infix_re = re.compile(r'''[-~]''') #find hyphens\n",
    "suffix_re = re.compile(r'''[,.\"']$''') #find , or . at end of word\n",
    "def customize_tokenizer(nlp):\n",
    "# Adds support to use `-` as the delimiter for tokenization\n",
    "    return Tokenizer(nlp.vocab, \n",
    "                     infix_finditer=infix_re.finditer,\n",
    "                     suffix_search=suffix_re.search, \n",
    "                     token_match=None)\n",
    "\n",
    "nlp.tokenizer = customize_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_adrs(adrs):\n",
    "    clean_adrs = ''\n",
    "    \n",
    "    #Tokenize the address using SpaCy tokenizer\n",
    "    adrs_parts = nlp(adrs)\n",
    "    #print ([token.text for token in adrs_parts])\n",
    "    \n",
    "    #Find the street number\n",
    "    last = 1\n",
    "    if str(adrs_parts[-1]) in punctuation:\n",
    "        number = adrs_parts[-2]\n",
    "        last = 2\n",
    "    else:\n",
    "        number = adrs_parts[-1]\n",
    "        \n",
    "    #Correction of errors\n",
    "    for i in range(len(adrs_parts)-last):\n",
    "        if adrs_parts[i].text in punctuation:\n",
    "            if adrs_parts[i].text == '-':\n",
    "                clean_adrs = clean_adrs[:-1] + adrs_parts[i].text\n",
    "        else:\n",
    "            clean_adrs += correction(adrs_parts[i].text).capitalize()\n",
    "            clean_adrs += ' '\n",
    "            \n",
    "    return clean_adrs + str(number)\n",
    "\n",
    "convert_adrs = {'av':'Avenue', \n",
    "        'r':'Rue', \n",
    "        'bd':'Boulevard',\n",
    "        'pl':'Place',\n",
    "        'fr':'Faubourg'}\n",
    "\n",
    "def clean_adrs(adrs):\n",
    "    adrs = correct_adrs(adrs)\n",
    "    adrs_part_punct = adrs.split()\n",
    "    adrs_part = remove_punct(adrs).split()\n",
    "    for i in range(len(adrs_part)):\n",
    "        if lowercase_all(adrs_part[i]) in convert_adrs:\n",
    "            adrs_part_punct[i] = convert_adrs[lowercase_all(adrs_part[i])]\n",
    "    adrs = ' '.join(adrs_part_punct)\n",
    "    return adrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accent(string):\n",
    "    string = string.replace('é','e')\n",
    "    string = string.replace('è','e')\n",
    "    string = string.replace('ê','e')\n",
    "    string = string.replace('ë','e')\n",
    "    string = string.replace('à','a')\n",
    "    string = string.replace('â','a')\n",
    "    string = string.replace('ô','o')\n",
    "    return string\n",
    "\n",
    "def simplest(string): #Return the simplest form (no punctuation, all lowercase, no accents) of a string\n",
    "    new_string = ''\n",
    "    if type(string) == str:\n",
    "        for c in string:\n",
    "            if c.isalpha():\n",
    "                new_string += c\n",
    "    return remove_punct(lowercase_all(remove_accent(new_string)))\n",
    "\n",
    "def simplest_adr(string): #Format: Avenue St-Honoré 21 -> avenuesthonore21\n",
    "    num = ''\n",
    "    if type(string) == str:\n",
    "        for c in string:\n",
    "            if c.isnumeric():\n",
    "                num += c   \n",
    "    return(simplest(string)+num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning our addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1884 = pd.read_csv('data/data_1884.csv')\n",
    "df_1908 = pd.read_csv('data/data_1908.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1884.Addresses = df_1884.Addresses.apply(clean_adrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1908.Addresses = df_1908.Addresses.apply(clean_adrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1884['Simplest'] = df_1884['Addresses'].apply(simplest_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1908['Simplest'] = df_1908['Addresses'].apply(simplest_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1884.to_csv('data/adr_1884_cleaned.csv')\n",
    "df_1908.to_csv('data/adr_1908_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1884 = pd.read_csv('data/adr_1884_cleaned.csv')\n",
    "df_1908 = pd.read_csv('data/adr_1908_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = pd.read_csv('data/All_nums.csv')\n",
    "coord['Simplest'] = coord['nom_entier'] + coord['num'].map(lambda x: str(x))\n",
    "coord['Simplest'] = coord['Simplest'].apply(simplest_adr)\n",
    "coord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1884_coord = df_1884.merge(coord[['Simplest', 'Y', 'X']], on = 'Simplest')\n",
    "df_1884_coord.drop(labels = ['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1908_coord = df_1908.merge(coord[['Simplest', 'Y', 'X']], on = 'Simplest')\n",
    "df_1908_coord.drop(labels = ['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For the year 1884, we have %d addresses with coordinates.\" %count_elmt(df_1884_coord))\n",
    "print(\"For the year 1908, we have %d addresses with coordinates.\" %count_elmt(df_1908_coord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1884_no_coord = pd.concat([df_1884,df_1884_coord], sort = True).drop_duplicates(subset = 'Simplest', keep = False)\n",
    "df_1908_no_coord = pd.concat([df_1908,df_1908_coord], sort = True).drop_duplicates(subset = 'Simplest', keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For the year 1884, we still have %d addresses without coordinates.\" %count_elmt(df_1884_no_coord))\n",
    "print(\"For the year 1908, we still have %d addresses without coordinates.\" %count_elmt(df_1908_no_coord))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
