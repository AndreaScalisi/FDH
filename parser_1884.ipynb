{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the data from the 1884 OCR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"beau_monde_1884_tables.xlsx\",header = None, sheet_name = None)\n",
    "column_names = ['Gender', 'de', 'Name', 'Adress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Cte</td>\n",
       "      <td>de Beaucaire.</td>\n",
       "      <td>B1 Haussman, 111.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bon</td>\n",
       "      <td>de Beaucaire.</td>\n",
       "      <td>. Rue de Rigny, 5.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>M. Me</td>\n",
       "      <td>de Beauchamp.</td>\n",
       "      <td>. R. de la Bienfaisance, 17.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M. Ml!</td>\n",
       "      <td>Beauchamp.</td>\n",
       "      <td>. Rue JoufTroy, 81.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Gse</td>\n",
       "      <td>de Beauchamp.</td>\n",
       "      <td>. Rue de l’Université; 70.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0              1                             2\n",
       "0     Cte  de Beaucaire.             B1 Haussman, 111.\n",
       "1     Bon  de Beaucaire.            . Rue de Rigny, 5.\n",
       "2   M. Me  de Beauchamp.  . R. de la Bienfaisance, 17.\n",
       "3  M. Ml!     Beauchamp.           . Rue JoufTroy, 81.\n",
       "4     Gse  de Beauchamp.    . Rue de l’Université; 70."
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['table_11'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning the addresses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text handling utilities\n",
    "from string import punctuation\n",
    "def lowercase_all(text):\n",
    "    return text.lower()\n",
    "def remove_punct(text):\n",
    "    return ''.join([ch for ch in text if ch not in punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spelling Corrector based on the work of Peter Norvig: http://norvig.com/spell-correct.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('list_addresses.txt', encoding='utf-8').read())) \n",
    "#list_addresses.txt is a hand-corrected list of addresses\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if (w.isalpha() and w.lower() in WORDS))\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SpaCy to tokenize the addresses. We just need to add some rules to deal with special cases (like the hyphen in St-Honoré or commas at the end of a word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "infix_re = re.compile(r'''[-~]''') #find hyphens\n",
    "suffix_re = re.compile(r'''[,.\"']$''') #find , or . at end of word\n",
    "def customize_tokenizer(nlp):\n",
    "# Adds support to use `-` as the delimiter for tokenization\n",
    "    return Tokenizer(nlp.vocab, \n",
    "                     infix_finditer=infix_re.finditer,\n",
    "                     suffix_search=suffix_re.search, \n",
    "                     token_match=None)\n",
    "\n",
    "nlp.tokenizer = customize_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define some functions to clean the addresses. The first one corrects spelling error and the second one harmonizes all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_adrs(adrs):\n",
    "    clean_adrs = ''\n",
    "    \n",
    "    #Tokenize the address using SpaCy tokenizer\n",
    "    adrs_parts = nlp(adrs)\n",
    "    #print ([token.text for token in adrs_parts])\n",
    "    \n",
    "    #Find the street number\n",
    "    last = 1\n",
    "    if str(adrs_parts[-1]) in punctuation:\n",
    "        number = adrs_parts[-2]\n",
    "        last = 2\n",
    "    else:\n",
    "        number = adrs_parts[-1]\n",
    "        \n",
    "    #Correction of errors\n",
    "    for i in range(len(adrs_parts)-last):\n",
    "        if str(adrs_parts[i]) in punctuation:\n",
    "            if str(adrs_parts[i]) == '-':\n",
    "                clean_adrs = clean_adrs[:-1] + str(adrs_parts[i])\n",
    "        else:\n",
    "            clean_adrs += correction(str(adrs_parts[i])).capitalize()\n",
    "            clean_adrs += ' '\n",
    "            \n",
    "    return clean_adrs + str(number)\n",
    "\n",
    "convert_adrs = {'av':'Avenue', \n",
    "        'r':'Rue', \n",
    "        'bd':'Boulevard',\n",
    "        'pl':'Place',\n",
    "        'fr':'Faubourg'}\n",
    "\n",
    "def clean_adrs(adrs):\n",
    "    adrs = correct_adrs(adrs)\n",
    "    adrs_part_punct = adrs.split()\n",
    "    adrs_part = remove_punct(adrs).split()\n",
    "    for i in range(len(adrs_part)):\n",
    "        if lowercase_all(adrs_part[i]) in convert_adrs:\n",
    "            adrs_part_punct[i] = convert_adrs[lowercase_all(adrs_part[i])]\n",
    "    adrs = ' '.join(adrs_part_punct)\n",
    "    return adrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have some tests (still need to get rid of NaN values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Faubourg St-Honoré 21'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_adrs = 'Ff S\\'-llonoré. 21'\n",
    "clean_adrs(test_adrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1 Haussman, 111. : Boulevard Haussman 111\n",
      ". Rue de Rigny, 5. : Rue De Rigny 5\n",
      ". R. de la Bienfaisance, 17. : Rue De La Bienfaisance 17\n",
      ". Rue JoufTroy, 81. : Rue Jouftroy 81\n",
      ". Rue de l’Université; 70. : Rue De L’université; 70\n",
      ". Av. d’Antin , 1. : Avenue Antin 1\n",
      ". Ba Malesherbes, 81. : La Malesherbes 81\n",
      ". Rue Bayard, 20. : Rue Bayard 20\n",
      ". Rue Miromesnil, 20. : Rue Miromesnil 20\n",
      ". Rue de Sèvres. 85. : Rue De Sèvres 85\n",
      ". Rue de Sèvres, 85. : Rue De Sèvres 85\n",
      ". Rue de Sèvres, 85. : Rue De Sèvres 85\n",
      ". Rue de Sèvres, 85. : Rue De Sèvres 85\n",
      ". Rue Royale, 8. : Rue Royale 8\n",
      ". Bd Malesherbes, 8. : Boulevard Malesherbes 8\n",
      "Rue Sl-Lazare, 89. : Rue L-Lazare 89\n",
      "Rue Ville-rÉvêque, 25. : Rue Ville-Révêque 25\n",
      "Rue Barbet-de-Jouy, 30. : Rue Barbet-De-Jouy 30\n",
      "Rue de Yerneuil, 43. : Rue De Yerneuil 43\n",
      "Cité Martignac, 6. : Cité Martignac 6\n",
      "Rue de Grenelle, 125. : Rue De Grenelle 125\n",
      "Rue Blanche, 44. : Rue Blanche 44\n",
      "Rue Miromesnil, 72. : Rue Miromesnil 72\n",
      "Bd Latour-Maubourg, 02. : Boulevard Latour-Maubourg 02\n",
      "Rue de Grenelle, 122. : Rue De Grenelle 122\n",
      "Rue Beaulant, 4. : Rue Beaulant 4\n",
      "Rue du Bac, 46. : Rue Du Bac 46\n",
      "Rue Miromesnil, 12. : Rue Miromesnil 12\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-5289db43bacc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0madr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'table_11'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclean_adrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "for adr in df['table_11'][2]:\n",
    "        print(adr + ' : ' + clean_adrs(adr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
