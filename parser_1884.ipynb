{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the number of elements\n",
    "def count_elmt(df):\n",
    "    return len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data from the 1884 OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = pd.read_excel(\"beau_monde_1884_tables.xlsx\", header = None, sheet_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['table_1'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count how many addresses we have to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_adr = 0\n",
    "for i in range(167):\n",
    "    table = 'table_' + str(i+1)\n",
    "    num_adr += count_elmt(df_dict[table])\n",
    "    \n",
    "print('At the beginning, we have %d addresses.' %num_adr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows with missing values (or nan values) do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for table in df_dict:\n",
    "    counter += df_dict[table].isna().sum().sum()\n",
    "print('There are %d missing values in our data.' %(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there a too many values to fill them in by hand, we will just get rid of the corresponding rows (at least for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in df_dict:\n",
    "    df_dict[table].dropna(inplace=True)\n",
    "    \n",
    "counter = 0\n",
    "for table in df_dict:\n",
    "    counter += df_dict[table].isna().sum().sum()\n",
    "print('Now, there are %d missing values in our data.' %(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now harmonize the format of all the dataframes. We want to end up with one dataframe with two colums: Name and Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "for i in range(167):\n",
    "    table = 'table_' + str(i+1)\n",
    "    cnt[str(len(df_dict[table].columns)) + ' columns'] += 1\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be different formats for the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(columns = [0,1])\n",
    "df_3 = pd.DataFrame(columns = [0,1,2])\n",
    "df_4 = pd.DataFrame(columns = [0,1,2,3])\n",
    "df_5 = pd.DataFrame(columns = [0,1,2,3,4])\n",
    "\n",
    "for i in range(167):\n",
    "    table = 'table_' + str(i+1)\n",
    "    if len(df_dict[table].columns) == 2: \n",
    "        df_2 = df_2.append(df_dict[table])\n",
    "    elif len(df_dict[table].columns) == 3: \n",
    "        df_3 = df_3.append(df_dict[table])\n",
    "    elif len(df_dict[table].columns) == 4:\n",
    "        df_4 = df_4.append(df_dict[table])\n",
    "    elif len(df_dict[table].columns) == 5:\n",
    "        df_5 = df_5.append(df_dict[table])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see those with 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head() #Just names, we can get rid of this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see those with 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['Names'] = df_3[0] + ' ' + df_3[1]\n",
    "df_3['Addresses'] = df_3[2]\n",
    "df_3.drop(labels = [0,1,2], axis = 1, inplace = True)\n",
    "df_3.reset_index(drop = True, inplace = True)\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see those with 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['Names'] = df_4[0].map(lambda x: str(x)) + ' ' + df_4[1].map(lambda x: str(x)) + ' ' + df_4[2].map(lambda x: str(x)) \n",
    "df_4['Addresses'] = df_4[3]\n",
    "df_4.drop(labels = [0,1,2,3], axis = 1, inplace = True)\n",
    "df_4.reset_index(drop = True, inplace = True)\n",
    "df_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see those with 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5['Names'] = df_5[0].map(lambda x: str(x)) + ' ' +  df_5[1].map(lambda x: str(x)) + ' ' + df_5[2].map(lambda x: str(x)) \n",
    "df_5['Addresses'] = df_5[3]\n",
    "df_5.drop(labels = [0,1,2,3,4], axis = 1, inplace = True)\n",
    "df_5.reset_index(drop = True, inplace = True)\n",
    "df_5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine them all in one single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_3, df_4, df_5])\n",
    "pre_cleaned = count_elmt(df)\n",
    "num_lost_adr = num_adr - pre_cleaned\n",
    "print('Before cleaning the strings, we have %d addresses.' %pre_cleaned)\n",
    "print('We have therefore lost %d%% addresses due to missing values.' %(100*num_lost_adr/num_adr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/data_to_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_to_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Corrector\n",
    "\n",
    "Spelling Corrector based on the work of Peter Norvig: http://norvig.com/spell-correct.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text handling utilities\n",
    "from string import punctuation\n",
    "def lowercase_all(text):\n",
    "    return text.lower()\n",
    "def remove_punct(text):\n",
    "    return ''.join([ch for ch in text if ch not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('list_addresses.txt', encoding='utf-8').read())) \n",
    "#list_addresses.txt is a hand-corrected list of addresses\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if (w.isalpha() and w.lower() in WORDS))\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SpaCy to tokenize the addresses. We just need to add some rules to deal with special cases (like the hyphen in St-Honor√© or commas at the end of a word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "infix_re = re.compile(r'''[-~]''') #find hyphens\n",
    "suffix_re = re.compile(r'''[,.\"']$''') #find , or . at end of word\n",
    "def customize_tokenizer(nlp):\n",
    "# Adds support to use `-` as the delimiter for tokenization\n",
    "    return Tokenizer(nlp.vocab, \n",
    "                     infix_finditer=infix_re.finditer,\n",
    "                     suffix_search=suffix_re.search, \n",
    "                     token_match=None)\n",
    "\n",
    "nlp.tokenizer = customize_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define some functions to clean the addresses. The first one corrects spelling error and the second one harmonizes all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_adrs(adrs):\n",
    "    clean_adrs = ''\n",
    "    \n",
    "    #Tokenize the address using SpaCy tokenizer\n",
    "    adrs_parts = nlp(adrs)\n",
    "    #print ([token.text for token in adrs_parts])\n",
    "    \n",
    "    #Find the street number\n",
    "    last = 1\n",
    "    if str(adrs_parts[-1]) in punctuation:\n",
    "        number = adrs_parts[-2]\n",
    "        last = 2\n",
    "    else:\n",
    "        number = adrs_parts[-1]\n",
    "        \n",
    "    #Correction of errors\n",
    "    for i in range(len(adrs_parts)-last):\n",
    "        if adrs_parts[i].text in punctuation:\n",
    "            if adrs_parts[i].text == '-':\n",
    "                clean_adrs = clean_adrs[:-1] + adrs_parts[i].text\n",
    "        else:\n",
    "            clean_adrs += correction(adrs_parts[i].text).capitalize()\n",
    "            clean_adrs += ' '\n",
    "            \n",
    "    return clean_adrs + str(number)\n",
    "\n",
    "convert_adrs = {'av':'Avenue', \n",
    "        'r':'Rue', \n",
    "        'bd':'Boulevard',\n",
    "        'pl':'Place',\n",
    "        'fr':'Faubourg'}\n",
    "\n",
    "def clean_adrs(adrs):\n",
    "    adrs = correct_adrs(adrs)\n",
    "    adrs_part_punct = adrs.split()\n",
    "    adrs_part = remove_punct(adrs).split()\n",
    "    for i in range(len(adrs_part)):\n",
    "        if lowercase_all(adrs_part[i]) in convert_adrs:\n",
    "            adrs_part_punct[i] = convert_adrs[lowercase_all(adrs_part[i])]\n",
    "    adrs = ' '.join(adrs_part_punct)\n",
    "    return adrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution time of this cell is quite long. Directly load the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.Addresses = df.Addresses.apply(clean_adrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/addresses_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('addresses_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some other preprocessing for the addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accent(string):\n",
    "    string = string.replace('√©','e')\n",
    "    string = string.replace('√®','e')\n",
    "    string = string.replace('√™','e')\n",
    "    string = string.replace('√´','e')\n",
    "    string = string.replace('√†','a')\n",
    "    string = string.replace('√¢','a')\n",
    "    string = string.replace('√¥','o')\n",
    "    return string\n",
    "\n",
    "def simplest(string): #Return the simplest form (no punctuation, all lowercase, no accents) of a string\n",
    "    new_string = ''\n",
    "    if type(string) == str:\n",
    "        for c in string:\n",
    "            if c.isalpha():\n",
    "                new_string += c\n",
    "    return remove_punct(lowercase_all(remove_accent(new_string)))\n",
    "\n",
    "def simplest_adr(string):\n",
    "    num = ''\n",
    "    if type(string) == str:\n",
    "        for c in string:\n",
    "            if c.isnumeric():\n",
    "                num += c   \n",
    "    return(simplest(string)+num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Simplest'] = df['Addresses'].apply(simplest_adr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a chunck of those addresses for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proto = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paris streets names**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a list of Paris addresses with the corresponding coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = pd.read_csv('All_nums.csv')\n",
    "coord['Simplest'] = coord['nom_entier'] + coord['num'].map(lambda x: str(x))\n",
    "coord['Simplest'] = coord['Simplest'].apply(simplest_adr)\n",
    "coord.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many addresses are already in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for adr in df.Simplest:\n",
    "    if adr in coord.Simplest.values:\n",
    "        count += 1\n",
    "print('%d are already in the Paris street coordinates database.' %count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now merge with the Paris addresses coordinates database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(coord[['Simplest', 'Y', 'X']], on = 'Simplest')\n",
    "df.drop(labels = ['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Addresses</th>\n",
       "      <th>Simplest</th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M¬∞ Adam Edmond .</td>\n",
       "      <td>Boulevard Poissonni√®re 23</td>\n",
       "      <td>boulevardpoissonniere23</td>\n",
       "      <td>48.871206</td>\n",
       "      <td>2.344183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M¬∞ Adam Edmond .</td>\n",
       "      <td>Boulevard Poissonni√®re 23</td>\n",
       "      <td>boulevardpoissonniere23</td>\n",
       "      <td>48.871136</td>\n",
       "      <td>2.344168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>M. M¬∞ Faure Antoine-Xavier.</td>\n",
       "      <td>Boulevard Poissonni√®re 23</td>\n",
       "      <td>boulevardpoissonniere23</td>\n",
       "      <td>48.871206</td>\n",
       "      <td>2.344183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M. M¬∞ Faure Antoine-Xavier.</td>\n",
       "      <td>Boulevard Poissonni√®re 23</td>\n",
       "      <td>boulevardpoissonniere23</td>\n",
       "      <td>48.871136</td>\n",
       "      <td>2.344168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Bno d‚Äô Adelsward.</td>\n",
       "      <td>Rue De La Bienfaisance,44</td>\n",
       "      <td>ruedelabienfaisance44</td>\n",
       "      <td>48.876625</td>\n",
       "      <td>2.314868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Names                  Addresses  \\\n",
       "0             M¬∞ Adam Edmond .  Boulevard Poissonni√®re 23   \n",
       "1             M¬∞ Adam Edmond .  Boulevard Poissonni√®re 23   \n",
       "2  M. M¬∞ Faure Antoine-Xavier.  Boulevard Poissonni√®re 23   \n",
       "3  M. M¬∞ Faure Antoine-Xavier.  Boulevard Poissonni√®re 23   \n",
       "4            Bno d‚Äô Adelsward.  Rue De La Bienfaisance,44   \n",
       "\n",
       "                  Simplest          Y         X  \n",
       "0  boulevardpoissonniere23  48.871206  2.344183  \n",
       "1  boulevardpoissonniere23  48.871136  2.344168  \n",
       "2  boulevardpoissonniere23  48.871206  2.344183  \n",
       "3  boulevardpoissonniere23  48.871136  2.344168  \n",
       "4    ruedelabienfaisance44  48.876625  2.314868  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/adr_coord.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Addresses</th>\n",
       "      <th>Simplest</th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M¬∞ Adam Edmond .</td>\n",
       "      <td>Boulevard Poissonni√®re 23</td>\n",
       "      <td>boulevardpoissonniere23</td>\n",
       "      <td>48.871206</td>\n",
       "      <td>2.344183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M¬∞ Adam Edmond .</td>\n",
       "      <td>Boulevard Poissonni√®re 23</td>\n",
       "      <td>boulevardpoissonniere23</td>\n",
       "      <td>48.871136</td>\n",
       "      <td>2.344168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>M. M¬∞ Faure Antoine-Xavier.</td>\n",
       "      <td>Boulevard Poissonni√®re 23</td>\n",
       "      <td>boulevardpoissonniere23</td>\n",
       "      <td>48.871206</td>\n",
       "      <td>2.344183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M. M¬∞ Faure Antoine-Xavier.</td>\n",
       "      <td>Boulevard Poissonni√®re 23</td>\n",
       "      <td>boulevardpoissonniere23</td>\n",
       "      <td>48.871136</td>\n",
       "      <td>2.344168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Bno d‚Äô Adelsward.</td>\n",
       "      <td>Rue De La Bienfaisance,44</td>\n",
       "      <td>ruedelabienfaisance44</td>\n",
       "      <td>48.876625</td>\n",
       "      <td>2.314868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Bon Jjne J‚Äô Adelsward Axel.</td>\n",
       "      <td>Rue Royale 10</td>\n",
       "      <td>rueroyale10</td>\n",
       "      <td>48.867992</td>\n",
       "      <td>2.323160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Bon Jjne J‚Äô Adelsward Axel.</td>\n",
       "      <td>Rue Royale 10</td>\n",
       "      <td>rueroyale10</td>\n",
       "      <td>48.854306</td>\n",
       "      <td>2.365062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Bon Jjne J‚Äô Adelsward Axel.</td>\n",
       "      <td>Rue Royale 10</td>\n",
       "      <td>rueroyale10</td>\n",
       "      <td>48.867852</td>\n",
       "      <td>2.323102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>M. Auffm-Ordt Cl√©ment..</td>\n",
       "      <td>Rue Royale 10</td>\n",
       "      <td>rueroyale10</td>\n",
       "      <td>48.867992</td>\n",
       "      <td>2.323160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>M. Auffm-Ordt Cl√©ment..</td>\n",
       "      <td>Rue Royale 10</td>\n",
       "      <td>rueroyale10</td>\n",
       "      <td>48.854306</td>\n",
       "      <td>2.365062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Names                  Addresses  \\\n",
       "0             M¬∞ Adam Edmond .  Boulevard Poissonni√®re 23   \n",
       "1             M¬∞ Adam Edmond .  Boulevard Poissonni√®re 23   \n",
       "2  M. M¬∞ Faure Antoine-Xavier.  Boulevard Poissonni√®re 23   \n",
       "3  M. M¬∞ Faure Antoine-Xavier.  Boulevard Poissonni√®re 23   \n",
       "4            Bno d‚Äô Adelsward.  Rue De La Bienfaisance,44   \n",
       "5  Bon Jjne J‚Äô Adelsward Axel.              Rue Royale 10   \n",
       "6  Bon Jjne J‚Äô Adelsward Axel.              Rue Royale 10   \n",
       "7  Bon Jjne J‚Äô Adelsward Axel.              Rue Royale 10   \n",
       "8      M. Auffm-Ordt Cl√©ment..              Rue Royale 10   \n",
       "9      M. Auffm-Ordt Cl√©ment..              Rue Royale 10   \n",
       "\n",
       "                  Simplest          Y         X  \n",
       "0  boulevardpoissonniere23  48.871206  2.344183  \n",
       "1  boulevardpoissonniere23  48.871136  2.344168  \n",
       "2  boulevardpoissonniere23  48.871206  2.344183  \n",
       "3  boulevardpoissonniere23  48.871136  2.344168  \n",
       "4    ruedelabienfaisance44  48.876625  2.314868  \n",
       "5              rueroyale10  48.867992  2.323160  \n",
       "6              rueroyale10  48.854306  2.365062  \n",
       "7              rueroyale10  48.867852  2.323102  \n",
       "8              rueroyale10  48.867992  2.323160  \n",
       "9              rueroyale10  48.854306  2.365062  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a dict to map all the abbreviations to the corresponding titles (we also include 'Monsieur', 'Madame' and 'Mademoiselle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "titres = {'Cte':'Comte', 'Cse':'Comtesse', 'Vte':'Vicomte', 'Vse':'Vicomtesse', 'Dc':'Duc', 'Dse':'Duchesse',\n",
    "         'Bon':'Baron', 'Bne':'Baronne', 'Mis':'Marquis', 'Mse':'Marquise', 'Pce':'Prince', 'M':'Monsieur', 'M¬∞':'Monsieur', \n",
    "          'Me':'Madame', 'Mlle':'Mademoiselle'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: add regex to find patterns of type \"' voyelle\" to get \"d'\" (ex: \"cl ' Adelsward\" doit donner \"d'Adelsward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    name_parts = nlp(name)\n",
    "    cleaned_name = ''\n",
    "    titre = ''\n",
    "    #print ([token.text for token in name_parts])\n",
    "    if name_parts[-1].text in punctuation:\n",
    "        name_parts = name_parts[:-1]\n",
    "    for i in range(len(name_parts)):\n",
    "        if name_parts[i].text in titres:\n",
    "            #print(name_parts[i].text)\n",
    "            titre += titres[remove_punct(name_parts[i].text)] #we add the corresponding title using the dict titres\n",
    "            titre += ' '\n",
    "        else: \n",
    "            cleaned_name += name_parts[i].text\n",
    "        cleaned_name += ' '\n",
    "    #print ([token.text for token in name_parts])\n",
    "    \n",
    "    return (titre,cleaned_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Baron Baronne ', \"  cl ' Adelsward Gustave \")"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'Bon Bne cl\\' Adelsward Gustave'\n",
    "clean_name(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           (Monsieur ,  Adam Edmond )\n",
       "1                           (Monsieur ,  Adam Edmond )\n",
       "2    (Monsieur Monsieur ,  .  Faure Antoine - Xavier )\n",
       "3    (Monsieur Monsieur ,  .  Faure Antoine - Xavier )\n",
       "4                                (, Bno d‚Äô Adelsward )\n",
       "5                   (Baron ,  Jjne J‚Äô Adelsward Axel )\n",
       "6                   (Baron ,  Jjne J‚Äô Adelsward Axel )\n",
       "7                   (Baron ,  Jjne J‚Äô Adelsward Axel )\n",
       "8              (Monsieur ,  . Auffm - Ordt Cl√©ment . )\n",
       "9              (Monsieur ,  . Auffm - Ordt Cl√©ment . )\n",
       "Name: Names, dtype: object"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10).Names.apply(clean_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
